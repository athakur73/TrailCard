{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06238f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5169e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPatient First Name: William\\nPatient Last Name: Hicks\\nRx#: 210280140357\\nDrug Name: INVOKANA TABS\\nNDC: 50458-0141-90\\nFilled date: 09/16/2021\\nDay supply: \\nQuantity: 90\\nAmount:\\nPrimary Paid Amount:\\nCopay: $120.00\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Patient First Name: William\n",
    "Patient Last Name: Hicks\n",
    "Rx#: 210280140357\n",
    "Drug Name: INVOKANA TABS\n",
    "NDC: 50458-0141-90\n",
    "Filled date: 09/16/2021\n",
    "Day supply: \n",
    "Quantity: 90\n",
    "Amount:\n",
    "Primary Paid Amount:\n",
    "Copay: $120.00\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20d537a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import re\n",
    "import os\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "stopwords = stopwords.words('english')\n",
    "path = r\"docs\"\n",
    "dir_list = os.listdir(path)\n",
    "\n",
    "\n",
    "data = dict()\n",
    "for file in dir_list:\n",
    "    mx = ''\n",
    "#     w, h = Image.open(path+'\\\\'+file).size\n",
    "#     mx = pytesseract.image_to_string(Image.open(path+'\\\\'+file).crop((0, 0, w, int(h/2))).convert('L'))\n",
    "    mx = pytesseract.image_to_string(Image.open(path+'\\\\'+file).convert('L'))\n",
    "    mx = mx.replace('\\n\\n',' ')\n",
    "    mx = mx.replace('\\n',' ')\n",
    "    res = []\n",
    "    for x in mx.split():\n",
    "        st = ' '.join([w for w in x.split() if w not in stopwords])\n",
    "        res.append(st)\n",
    "    data[file.split('.')[0]] = ' '.join(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7127d981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Promised: 8/14/21, 10\\'24 AM WAITING oieo Resyri” B GR T Gross, Margaret 105 Brown Street Sulte 200, Tecumseh, MI DOB: 953 TEL: (517)902-1370 www. Cvs. comvdruginfo Prescription Information \\' ODACTRA 12 SQ-HDM SL | @ TABLET Place 1 tablet   tongue AROAY  daily. Revisit needed  tal - additional refills. EVENING = | IrBReSIANARLEBARSE:  tongue. Do  chew  LG swallow whole. See 3ok  e Mammation | = DO O eat  drink anything  5 minutes  taking  medication. - Wash hands  use - Save time  ReadyFill  we\\'ll   refills ready  you. Ask  enrolling today! Receipt & Refill Information ~ CVS Pharmacy BO7 Wast Chicago Biv Tecumseh, Mi 49286 srorers0s | ODACTRA 12 SQ-HDM SL TABLET rx: 1953336 07 QTY: 30 EA INSURANCE INFORMATION: PDP BNE10011 PNCTRXMEDD CAP: Safety 1P 2404 6% ZGWPSIN AUTW 2122632022670369%% MFR PKG: Yes REFILL: 4  11/17/21 MFR: ALK-ABELLO, INC PRSCBR: Georgiana Sanders DAYS SUPPLY: 30 . = DATE FILLED: 8/14/21 RETAIL PRICE:$388.99 | AMOUNT DUE: $158.88 Notes   Pharmacy This medication   regularly stocked   pharmacy. To   Rx ready  time, please refill two business days  advance  need date. For  information please contact  pharmacy. ®CVS pharmacy’ oEe P ¥ CVS pharmacy’ 807 u T 7 CH HB ECU 42 66 REG#19 TRNEE828 CSHRE1S: BLVD 286 oM Al SEH., 17 wxv— 9 6 5946 STR#8UZE f\\\\ ~NNO Helped by. ANNA F 1 RX #: #x%%3360070 158 . 88N Survey ID # TOTAL 158. CHARGE 18333 EREXBERXXXXRDTLE RF CHASE VISR xARpARERERE DGR APPROVEDH 067710 REF# 198282 TRAN TYP: SALE ALl 7 C0000GU31010 IE: bZ[LL-.S?ﬂ)BH]f 5  NALH 81723007 NO SIGNf\\\\T\"\"C D{\\'Q\\' Cvit. 1FO000 TVR(95): { Qbf‘L) TSI(SB}: 0000 CHANGE R A IIl I 3508 0251 2286 8281 94 State law may Prohlblf  return  prescriptions. Please consult  pharmacist. Returns  receipt, sublect CVS Return Policy, thru 10/16/2021 efund amount  based  price   coupons  dlscounts. AUGUST 16, 2021 2:15 PH Doy DD DO DD'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13914e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('data.pkl','wb') as fd:\n",
    "    pickle.dump(data,fd,pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6d393a",
   "metadata": {},
   "source": [
    "## Using spacy PhaseMatcher for extracting name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e8cd8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "# !python -m spacy download en\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "775c5b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Georgiana Sanders\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "from nltk.corpus import words\n",
    "import re\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
    "\n",
    "nlp_hf = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "nlp_1 = spacy.load(\"en_core_web_sm\")\n",
    "nlp_2 = spacy.load(\"en_core_web_trf\")\n",
    "\n",
    "eng_dict_words = set(words.words())\n",
    "eng_dict_words.add('oniine')\n",
    "\n",
    "def ner_detect_spacy_and_hugging_face(text):                         \n",
    "    \n",
    "    \n",
    "    #spacy\n",
    "    \n",
    "    text = text.replace(',','')\n",
    "    sents = nlp_1(text)\n",
    "\n",
    "    names_list_1 = []\n",
    "    \n",
    "    for entity in sents.ents:\n",
    "        if entity.label_ == 'PERSON':\n",
    "            # print('spacy persons',str(entity))\n",
    "            # check if word in dict, removing last char to account for plural\n",
    "            if (not all(( ((w in eng_dict_words) or (w.rstrip('s') in eng_dict_words)) for w in re.sub(r'[^\\w\\s]','',str(entity).lower()).split())) and (not any(char.isdigit() for char in str(entity)))):\n",
    "                  if 14>max([len(m) for m in str(entity).split()])>3: # length of name limt\n",
    "                    names_list_1.append(str(entity))\n",
    "    \n",
    "    sents = nlp_2(text)\n",
    "    names_list_2 = []\n",
    "    \n",
    "    for entity in sents.ents:\n",
    "        if entity.label_ == 'PERSON':\n",
    "            # print('spacy persons',str(entity))\n",
    "            # check if word in dict, removing last char to account for plural\n",
    "            if (not all(( ((w in eng_dict_words) or (w.rstrip('s') in eng_dict_words)) for w in re.sub(r'[^\\w\\s]','',str(entity).lower()).split())) and (not any(char.isdigit() for char in str(entity)))):\n",
    "              if 14>max([len(m) for m in str(entity).split()])>3: # length of name limt\n",
    "                    names_list_2.append(str(entity))\n",
    "                    \n",
    "    \n",
    "    # hugging face transformers\n",
    "    names_list_3= []\n",
    "    \n",
    "    list_words = text.split()\n",
    "    ner_results = nlp_hf(text)\n",
    "    for i in range(len(ner_results)):\n",
    "        if ner_results[i]['score']>0.65:\n",
    "            k= ner_results[i]['entity'] == 'I-PER' or ner_results[i]['entity'] == 'B-PER'\n",
    "            if k==True:\n",
    "              names_list_3.append(ner_results[i]['word'])\n",
    "    \n",
    "    \n",
    "    # combine all the lists\n",
    "    names_list = []\n",
    "    for indd in range(max(len(names_list_1),len(names_list_2),len(names_list_3))):\n",
    "        if indd<len(names_list_1):\n",
    "            names_list.append(names_list_1[indd])\n",
    "        \n",
    "        if indd<len(names_list_2):\n",
    "            names_list.append(names_list_2[indd])\n",
    "            \n",
    "        if indd<len(names_list_3):\n",
    "            names_list.append(names_list_3[indd])\n",
    "                    \n",
    "    \n",
    "    # post processing the lists\n",
    "           \n",
    "    found_names =[]\n",
    "    for name in names_list: # name assumed to be the first two-word string\n",
    "        if len(name.split())>1:\n",
    "            found_names.append(name)\n",
    "    \n",
    "    if not found_names:\n",
    "        # regex for all caps words\n",
    "        matches = re.findall(r\"([A-Z]+\\s?[A-Z]+[^a-z0-9\\W])\",text)\n",
    "        for match in matches:\n",
    "            if len(match.split())>1:\n",
    "                if not all(m in eng_dict_words for m in match.lower().split()): # must not be both english words\n",
    "                    if 14>max([len(m) for m in match.split()])>3: # at leaset one four letter word\n",
    "                        found_names.append(match)\n",
    "                        \n",
    "    # filter some names\n",
    "    found_names_filtered = found_names.copy()\n",
    "    for name in found_names:\n",
    "        for word in name.split():\n",
    "            if ('tab' in word.lower()) or ('invoice' in word.lower()):\n",
    "                found_names_filtered.remove(name)\n",
    "    \n",
    "    return found_names_filtered\n",
    "\n",
    "\n",
    "\n",
    "for i in range(1,26):\n",
    "    if i<10:\n",
    "        continue\n",
    "    if(i not in [10,25]):\n",
    "        #print('i',i)\n",
    "        names = ner_detect_spacy_and_hugging_face(data[str(i)])\n",
    "        print(names[0])\n",
    "    else:\n",
    "        print('')\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2a2fb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
